{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number rows and columns\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of empty values in each column\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column with all missing values\n",
    "\n",
    "df = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of Malignant (M) or Benign (B) cells\n",
    "\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the count\n",
    "\n",
    "sns.countplot(x=df['diagnosis'], label='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data types to see which columns need to be encoded\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the categorical data values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder_y = LabelEncoder()\n",
    "\n",
    "df.iloc[:,1] = labelencoder_y.fit_transform(df.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pair plots\n",
    "\n",
    "sns.pairplot(df.iloc[:,1:6], hue='diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 rows of the new data\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correlation of the columns\n",
    "\n",
    "df.iloc[:,1:12].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,9))\n",
    "\n",
    "sns.heatmap(df.iloc[:,1:12].corr(), annot=True, fmt='.0%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set into independent (X) and dependent (Y) data sets\n",
    "\n",
    "X = df.iloc[:,2:31].values\n",
    "Y = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set into 75% training and 25% testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data (feature scaling)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for the models\n",
    "\n",
    "def models(X_train, Y_train):\n",
    "    \n",
    "    # logistic regression\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    log = LogisticRegression(random_state=0)\n",
    "    log.fit(X_train, Y_train)\n",
    "\n",
    "    # decision tree\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    tree = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    tree.fit(X_train, Y_train)\n",
    "\n",
    "    # random forest classifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    forest = RandomForestClassifier(n_estimators = 10, criterion='entropy', random_state=0)\n",
    "    forest.fit(X_train, Y_train)\n",
    "\n",
    "    # print the models accuracy on the training data\n",
    "    print('[0] Logistic Regression Training Accuracy:\\t', log.score(X_train, Y_train))\n",
    "    print('[1] Decision Tree Classifier Training Accuracy:\\t', tree.score(X_train, Y_train))\n",
    "    print('[2] Random Forest Classifier Training Accuracy:\\t', forest.score(X_train, Y_train))\n",
    "\n",
    "    return log, tree, forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# throws an error otherwise\n",
    "Y_train = np.array(Y_train, dtype=int)\n",
    "Y_test = np.array(Y_test, dtype=int)\n",
    "\n",
    "# getting all of the models\n",
    "model = models(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model accuracy on test data on confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model_names = { 0: \"Logistic Regression\", 1: \"Decision Tree Classifier\", 2: \"Random Forest Classifier\" }\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "for i in range(len(model)):\n",
    "    print(\"Model:\", model_names[i])\n",
    "    cm = confusion_matrix(Y_test, model[i].predict(X_test))\n",
    "\n",
    "    TP = cm[0][0]\n",
    "    TN = cm[1][1]\n",
    "    FN = cm[1][0]\n",
    "    FP = cm[0][1]\n",
    "\n",
    "    print(cm)\n",
    "    print('Testing Accuracy =',(TP + TN)/(TP + TN + FP + FN))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faster way to get metrics of the models\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "for i in range(len(model)):\n",
    "    print(\"Model:\", model_names[i], \"\\n\")\n",
    "\n",
    "    print(classification_report(Y_test, model[i].predict(X_test)))\n",
    "    print(\"Accuracy:\", accuracy_score(Y_test, model[i].predict(X_test)))\n",
    "    \n",
    "    print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Justification\n",
    "\n",
    "After evaluating three different models - Logistic Regression, Decision Tree Classifier, and Random Forest Classifier - on the chest cancer classification task, the **Random Forest Classifier** was identified as the most suitable model for the following reasons:\n",
    "\n",
    "## 1. Performance Metrics\n",
    "\n",
    "- **Accuracy**: The Random Forest model achieved the highest accuracy (96.5%), indicating its superior ability to correctly classify both cancerous and non-cancerous cases compared to the other models tested.\n",
    "- **Precision and Recall**: This model demonstrated very high precision and recall across both classes. Specifically, it showed a high ability to minimize false positives (precision) and false negatives (recall), which are crucial in medical diagnosis contexts. High recall is especially important for cancer detection to ensure that as few cases as possible are missed.\n",
    "- **F1-Score**: The balanced F1-scores across classes suggest that the model maintains a balanced performance between precision and recall, which is essential for the sensitive nature of cancer classification tasks.\n",
    "\n",
    "## 2. Importance of Recall in Medical Diagnostics\n",
    "\n",
    "Given the critical importance of minimizing false negatives (missing a cancer diagnosis) in medical diagnostics, a model's recall is highly valued. The Random Forest Classifier demonstrated excellent recall, making it a prudent choice for applications where missing a positive case could have significant consequences.\n",
    "\n",
    "## 3. Model Complexity vs. Interpretability\n",
    "\n",
    "While the Random Forest Classifier is more complex and slightly less interpretable than simpler models like Logistic Regression, its superior performance metrics justify its selection. However, it's essential to balance model complexity with the need for interpretability in a clinical setting. Advanced techniques and tools can be employed to interpret Random Forest models, making them more understandable to healthcare professionals.\n",
    "\n",
    "## 4. Conclusion\n",
    "\n",
    "Considering the high stakes involved in cancer diagnosis, the Random Forest Classifier's superior ability to accurately identify cancerous cases, coupled with its robust performance across various metrics, makes it the best choice among the evaluated models. Future work could involve exploring model interpretability improvements to enhance clinical usability and patient outcomes further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the preferred model - in this case the random forest classifier - to use it externally\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model[2], 'random_forest_classifier.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
